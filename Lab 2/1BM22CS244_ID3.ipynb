{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantoshJambagi2004/Machine_Learning/blob/main/1BM22CS244_ID3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample weather dataset\n",
        "data = {\n",
        "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
        "    'Windy': ['No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n",
        "    'Play Tennis?': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Function to calculate entropy\n",
        "def entropy(target):\n",
        "    # Get the counts of each class\n",
        "    class_counts = target.value_counts()\n",
        "    # Calculate the entropy using the formula\n",
        "    probabilities = class_counts / len(target)\n",
        "    return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "# Function to calculate information gain\n",
        "def information_gain(data, feature, target):\n",
        "    # Calculate the entropy of the whole dataset\n",
        "    entropy_before = entropy(target)\n",
        "\n",
        "    # Get the unique values of the feature\n",
        "    feature_values = data[feature].unique()\n",
        "\n",
        "    # Calculate the weighted entropy after the split\n",
        "    weighted_entropy = 0\n",
        "    for value in feature_values:\n",
        "        subset = target[data[feature] == value]\n",
        "        weighted_entropy += (len(subset) / len(target)) * entropy(subset)\n",
        "\n",
        "    # Information gain is the reduction in entropy\n",
        "    return entropy_before - weighted_entropy\n",
        "\n",
        "# Function to print entropy and information gain for each feature\n",
        "def print_entropy_and_gain(data, features, target):\n",
        "    print(\"\\nEntropy and Information Gain for each feature:\")\n",
        "    for feature in features:\n",
        "        gain = information_gain(data, feature, target)\n",
        "        ent = entropy(target)\n",
        "        print(f\"Feature: {feature} | Entropy: {ent:.4f} | Information Gain: {gain:.4f}\")\n",
        "\n",
        "# Function to build the decision tree recursively\n",
        "def build_tree(data, target, features):\n",
        "    # Base case: If all target values are the same, return a leaf node\n",
        "    if len(target.unique()) == 1:\n",
        "        return target.iloc[0]\n",
        "\n",
        "    # Base case: If no features left to split, return the majority class\n",
        "    if len(features) == 0:\n",
        "        return target.mode()[0]\n",
        "\n",
        "    # Calculate information gain for each feature\n",
        "    gains = {feature: information_gain(data, feature, target) for feature in features}\n",
        "\n",
        "    # Find the feature with the highest information gain\n",
        "    best_feature = max(gains, key=gains.get)\n",
        "\n",
        "    # Create the tree node with the best feature\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    # Get the unique values of the best feature\n",
        "    feature_values = data[best_feature].unique()\n",
        "\n",
        "    # Recursively build the tree for each subset of the data\n",
        "    for value in feature_values:\n",
        "        subset_data = data[data[best_feature] == value]\n",
        "        subset_target = target[data[best_feature] == value]\n",
        "\n",
        "        # Remove the best feature from the list of features for the next level\n",
        "        remaining_features = [f for f in features if f != best_feature]\n",
        "\n",
        "        # Build the subtree for the subset\n",
        "        subtree = build_tree(subset_data, subset_target, remaining_features)\n",
        "\n",
        "        # Add the subtree to the tree\n",
        "        tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Function to print the tree in a visually structured way\n",
        "def print_tree(tree, indent=\"\"):\n",
        "    if isinstance(tree, dict):\n",
        "        for feature, branches in tree.items():\n",
        "            print(f\"{indent}{feature}:\")\n",
        "            for value, subtree in branches.items():\n",
        "                print(f\"{indent}  {value} ->\", end=\" \")\n",
        "                print_tree(subtree, indent + \"    \")\n",
        "    else:\n",
        "        print(f\"{indent}{tree}\")\n",
        "\n",
        "# Target variable\n",
        "target = df['Play Tennis?']\n",
        "\n",
        "# Features\n",
        "features = ['Outlook', 'Temperature', 'Humidity', 'Windy']\n",
        "\n",
        "# Step 1: Print entropy and information gain for each feature\n",
        "print_entropy_and_gain(df, features, target)\n",
        "\n",
        "# Step 2: Build the decision tree\n",
        "tree = build_tree(df, target, features)\n",
        "\n",
        "# Step 3: Print the decision tree (formatted)\n",
        "print(\"\\nDecision Tree:\")\n",
        "print_tree(tree, indent=\"    \")\n",
        "\n"
      ],
      "metadata": {
        "id": "sNhBWIga3Wmw",
        "outputId": "6dd26354-7371-40b2-8c3e-eaa9a5a9178e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entropy and Information Gain for each feature:\n",
            "Feature: Outlook | Entropy: 0.9403 | Information Gain: 0.2467\n",
            "Feature: Temperature | Entropy: 0.9403 | Information Gain: 0.0292\n",
            "Feature: Humidity | Entropy: 0.9403 | Information Gain: 0.1518\n",
            "Feature: Windy | Entropy: 0.9403 | Information Gain: 0.0481\n",
            "\n",
            "Decision Tree:\n",
            "    Outlook:\n",
            "      Sunny ->         Humidity:\n",
            "          High ->             No\n",
            "          Normal ->             Yes\n",
            "      Overcast ->         Yes\n",
            "      Rain ->         Windy:\n",
            "          No ->             Yes\n",
            "          Yes ->             No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample weather dataset\n",
        "data = {\n",
        "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
        "    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
        "    'Windy': ['No', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'No', 'No', 'Yes', 'Yes', 'No', 'Yes'],\n",
        "    'Play Tennis?': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "# Function to calculate entropy\n",
        "def entropy(target):\n",
        "    # Get the counts of each class\n",
        "    class_counts = target.value_counts()\n",
        "    # Calculate the entropy using the formula\n",
        "    probabilities = class_counts / len(target)\n",
        "    return -np.sum(probabilities * np.log2(probabilities))\n",
        "\n",
        "# Function to calculate information gain\n",
        "def information_gain(data, feature, target):\n",
        "    # Calculate the entropy of the whole dataset\n",
        "    entropy_before = entropy(target)\n",
        "\n",
        "    # Get the unique values of the feature\n",
        "    feature_values = data[feature].unique()\n",
        "\n",
        "    # Calculate the weighted entropy after the split\n",
        "    weighted_entropy = 0\n",
        "    for value in feature_values:\n",
        "        subset = target[data[feature] == value]\n",
        "        weighted_entropy += (len(subset) / len(target)) * entropy(subset)\n",
        "\n",
        "    # Information gain is the reduction in entropy\n",
        "    return entropy_before - weighted_entropy\n",
        "\n",
        "# Target variable\n",
        "target = df['Play Tennis?']\n",
        "\n",
        "# Calculate information gain for each feature\n",
        "features = ['Outlook', 'Temperature', 'Humidity', 'Windy']\n",
        "gains = {feature: information_gain(df, feature, target) for feature in features}\n",
        "\n",
        "# Print the information gains\n",
        "print(\"Information Gain for each feature:\")\n",
        "for feature, gain in gains.items():\n",
        "    print(f\"{feature}: {gain:.4f}\")\n",
        "\n",
        "# Find the feature with the highest information gain\n",
        "best_feature = max(gains, key=gains.get)\n",
        "print(f\"The best feature to split on is: {best_feature}\")"
      ],
      "metadata": {
        "id": "rQA3PBcn82jV",
        "outputId": "f44adc2e-225c-4b96-cc23-f53a57c882c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Information Gain for each feature:\n",
            "Outlook: 0.2467\n",
            "Temperature: 0.0292\n",
            "Humidity: 0.1518\n",
            "Windy: 0.0481\n",
            "The best feature to split on is: Outlook\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}